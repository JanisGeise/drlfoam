#!/bin/bash
#SBATCH --partition=standard
#SBATCH --nodes=1
#SBATCH --time=150:00:00
#SBATCH --job-name=drl_train
#SBATCH --ntasks-per-node=2

module load python/3.8.2

# adjust path if necessary
source ~/drlfoam/pydrl/bin/activate
source ~/drlfoam/setup-env --container

# start a training with a buffer size of 8 and 8 runners;
# save output to log.test_training
# python3 run_training.py -o "e100_r5_b5_f0.8" -e slurm -b 5 -r 5 -i 100 -m 0 -s "cylinder2D" &> log.training
python3 run_training.py -o "e2_r2_b2_f1.5_every_2nd_dt_mixer_TEST" -e slurm -b 2 -r 2 -i 2 -m 0 -s "mixerVesselAMI" &> log.training

# run a training with the weirOverflow case
# python3 run_training.py -o "e100_r5_b5_f80" -e slurm -b 5 -r 5 -i 100 -m 0 -s "weirOverflow" &> log.training


