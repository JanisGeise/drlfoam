"""
implements a class which checks if a trajectory is valid or invalid
"""
import logging
import torch as pt

from typing import Union, List

from ...constants import DEFAULT_TENSOR_TYPE

logger = logging.getLogger(__name__)
pt.set_default_tensor_type(DEFAULT_TENSOR_TYPE)


class CheckTrajectories:
    def __init__(self, buffer_size: int, keys: list = None, sf: float = 0.25):
        """
        implements a class which checks if a trajectory is valid or invalid

        :param buffer_size: buffer size
        :param keys: key names to check
        :param sf: a safety factor for the boundaries to increase the range in which a trajectory is seen as valid
        """
        self._keys = ["cy", "cx", "alpha", "beta", "states"] if keys is None else keys
        self._buffer_size = buffer_size
        self._sf = sf

        # initialize with placeholder bounds
        self._current_bounds = {k: [-1e5, 1e5] for k in self._keys}
        self._valid = {k: True for k in self._keys}
        self._values = {}

    def update_last_bounds(self, data: Union[dict, List[dict]], min_max: dict) -> None:
        """
        update the boundaries in which a trajectory is seen as valid based on the trajectories generated in the
        previous episode

        :param data: trajectories from the previous episode
        :param min_max: min. and max. values used for normalization within the dataloader class
        :return: None
        """
        if type(data) is list:
            # resort from list(dict) (as stored in the buffer) to dict (as stored in all other cases); in that case the
            # buffer is already resorted to cx_*, cy_*, ... so we can't use the self._keys directly
            # (instead we use startswith() to get the correct key)
            data = {k: pt.cat([i[k].unsqueeze(-1) for i in data], dim=1) for k in data[0].keys()}
            rescale = False
        else:
            rescale = True

        # compute the new boundaries
        for k in data.keys():
            # no need to rescale alpha_* and beta_*
            if not k.startswith("min_max") and (k.startswith("alpha") or k.startswith("beta")):
                self._current_bounds[k] = [(data[k].min() - self._sf * data[k].min().abs()).item(),
                                           (data[k].max() + self._sf * data[k].max()).item()]
                continue

            elif not k.startswith("min_max") and not k.startswith("rewards"):
                # rescale to original value range and update bounds, min.- max. values are global for all _* parameter
                # groups (all cy_* are used to determine min._max._values); so we can't use k directly
                # (only if CFD data loaded, else the data is already re-scaled)
                tmp = self._rescale(data[k], min_max[k.split("_")[0]]) if rescale else data[k]
                self._current_bounds[k] = [(tmp.min() - self._sf * tmp.min().abs()).item(),
                                           (tmp.max() + self._sf * tmp.max()).item()]

        # if we have cx_*, we need to resort it so we can update the cy, cx, ... bounds
        if "cx_a" in data.keys():
            for k in ["cx", "cy", "alpha", "beta"]:
                tmp = pt.tensor([self._current_bounds[f"{k}_{i}"] for i in ["a", "b", "c"] if f"{k}_{i}" in data.keys()])
                self._current_bounds[k] = [tmp.min().item(), tmp.max().item()]

    def check_trajectories(self, data: dict) -> bool:
        """
        check all specified trajectories for validity

        :param data: trajectories generated by the environment models
        :return: True if all values are within the specified bounds
        """
        # loop over all quantities to check
        for key, value in data.items():
            if key != "generated_by" and self._check_conditions(value, key):
                # mark as invalid and append min/max/mean values of the trajectory (or if any NaN's inside)
                self._valid[key] = False
                self._values[key] = (value.min(), value.max(), value.mean())

        return all([i for i in self._valid.values()])

    def _check_conditions(self, trajectory: pt.Tensor, key: str) -> bool:
        """
        check a specific trajectory for validity

        :param trajectory: trajectory to check
        :param key: name of the trajectory within the keys list
        :return:
        """
        return ((trajectory.min().item() < self._current_bounds[key][0]) or
                (trajectory.max().item() > self._current_bounds[key][1]) or
                (pt.isnan(trajectory).any().item()))

    def print_info(self, i: int, no: int) -> None:
        """
        display some information for invalid trajectories, which values were out of bounds, etc.

        :param i: current number of trials to generate the trajectory
        :param no: trajectory number within the buffer
        :return: None
        """
        # if self._values contains entries, loop over all keys and print the infos
        if self._values:
            logger.info(f"Discarding trajectory {no + 1}/{self._buffer_size} due to invalid values [try no. {i}]:")
            for key, value in self._values.items():
                logger.info(f"\n\t(min, max, mean) for {key}: {round(value[0].item(), 5)}, {round(value[1].item(), 5)},"
                            f" {round(value[2].item(), 5)}\tbounds: ({round(self._current_bounds[key][0], 3)} "
                            f"{round(self._current_bounds[key][1], 3)})")

        # reset self._values and self._valid for the next trajectory
        self.reset()

    def reset(self) -> None:
        """
        reset self._values and self._valid for the next trajectory

        :return: None
        """
        self._valid = {k: True for k in self._keys}
        self._values = {}

    @staticmethod
    def _rescale(x: pt.Tensor, min_max_x: list) -> pt.Tensor:
        """
        reverse the normalization of the data

        :param x: normalized data
        :param min_max_x: min- and max-value used for normalizing the data
        :return: rescale data as tensor
        """
        # x = (x_max - x_min) * x_norm + x_min
        return (min_max_x[1] - min_max_x[0]) * x + min_max_x[0]


if __name__ == "__main__":
    pass
